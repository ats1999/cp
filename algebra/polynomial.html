
<!doctype html>
<html>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="UTF-8">
    <base href="https://cp-algorithms.com"/>
    <title>Operations on polynomials and series  - Competitive Programming Algorithms</title>
    <script src="https://e-maxx-eng.github.io/e-maxx-eng/js/jq.js"></script>
    <script src="https://e-maxx-eng.github.io/e-maxx-eng/js/common.js"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <link rel="stylesheet" href="https://e-maxx-eng.github.io/e-maxx-eng/css/common.css"/>

    <!-- highlightjs for code highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/styles/xcode.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <!-- end highlightjs -->
    <meta name="google-site-verification" content="qSnbeMPNVgZ3kIpGVsPIAPIvEdwYSg583kPdwgJtFO8" />
    <meta name="yandex-verification" content="f327630b02a1e115" />
</head>
<body data-v="2021-04-09:11085/5227 2021-04-08:11726/5372 2021-04-07:13654/6237 2021-04-06:11712/5778 2021-04-05:12035/5549 2021-04-04:10850/5064 2021-04-03:10290/4974">
<div id="container">
    <div id="navbar">
        <span id="title">
            <a href="./">CP-Algorithms</a>
        </span>
        <span id="menu">
            <a href="https://github.com/e-maxx-eng/e-maxx-eng/commits/master/src/algebra/polynomial.md" title="Changes History">Page Authors</a>
        </span>
        <span id="search" style="display:inline-block;width:200px;float:right;margin-top:7px;margin-right:20px;">
            <div class="ya-site-form ya-site-form_inited_no" onclick="return {'action':'https://cp-algorithms.com/search-results.html','arrow':false,'bg':'transparent','fontsize':12,'fg':'#000000','language':'en','logo':'rb','publicname':'search e-maxx-eng','suggest':true,'target':'_self','tld':'com','type':2,'usebigdictionary':true,'searchid':2314495,'input_fg':'#000000','input_bg':'#ffffff','input_fontStyle':'normal','input_fontWeight':'normal','input_placeholder':null,'input_placeholderColor':'#000000','input_borderColor':'#7f9db9'}"><form action="https://yandex.com/search/site/" method="get" target="_self" accept-charset="utf-8"><input type="hidden" name="searchid" value="2314495"/><input type="hidden" name="l10n" value="en"/><input type="hidden" name="reqenc" value=""/><input type="search" name="text" value=""/><input type="submit" value="Search"/></form></div><style type="text/css">.ya-page_js_yes .ya-site-form_inited_no { display: none; }</style><script type="text/javascript">(function(w,d,c){var s=d.createElement('script'),h=d.getElementsByTagName('script')[0],e=d.documentElement;if((' '+e.className+' ').indexOf(' ya-page_js_yes ')===-1){e.className+=' ya-page_js_yes';}s.type='text/javascript';s.async=true;s.charset='utf-8';s.src=(d.location.protocol==='https:'?'https:':'http:')+'//site.yandex.net/v2.0/js/all.js';h.parentNode.insertBefore(s,h);(w[c]||(w[c]=[])).push(function(){Ya.Site.Form.init()})})(window,document,'yandex_site_callbacks');</script>
        </span>
    </div>
<h1>Operations on polynomials and series</h1>

<p>In this article we will cover common operations that you will probably have to do if you deal with polynomials.</p>

<h2>Basic Notion and Facts</h2>

<p>Consider a polynomial $A(x) = a_0 + a_1 x + \dots + a_n x^n$ such that $a_n \neq 0$.</p>

<ul>
<li>For simplicity we will write $A$ instead of $A(x)$ wherever possible, which will be understandable from the context.</li>
<li>We will define the degree of polynomial $A$ as $\deg A = n$. It is convenient to say that $\deg A = -\infty$ for $A(x) = 0$.</li>
<li>For arbitrary polynomials $A$ and $B$ it holds that $\deg AB = \deg A + \deg B$.</li>
<li>Polynomials form an euclidean ring which means that for any polynomials $A$ and $B \neq 0$ we can uniquely represent $A$ as: $$A = D \cdot B + R,~ \deg R &lt; \deg B.$$ Here $R$ is called remainder of $A$ modulo $B$ and $D$ is called quotient.</li>
<li>If $A$ and $B$ have the same remainder modulo $C$, they're said to be equivalent modulo $C$, which is denoted as: $$A \equiv B \pmod{C}$$</li>
<li>For any linear polynomial $x-r$ it holds that: $$A(x) \equiv A(r) \pmod{x-r}$$</li>
<li>In particular: $$A(r) = 0 \iff A(x) \equiv 0 \pmod {x-r}$$ Which means that $A$ is divisible by $x-r$ $\iff$ $A(r)=0$.</li>
<li>If $A \equiv B \pmod{C \cdot D}$ then $A \equiv B \pmod{C}$</li>
<li>$A \equiv a_0 + a_1 x + \dots + a_{k-1} x^{k-1} \pmod{x^k}$</li>
</ul>

<h2>Basic implementation</h2>

<p><a href="https://github.com/e-maxx-eng/e-maxx-eng-aux/blob/master/src/polynomial.cpp">Here</a> you can find the basic implementation of polynomial algebra.</p>

<p>It supports all trivial operations and some other useful methods. The main class is <code>poly&lt;T&gt;</code> for polynomials with coefficients of class <code>T</code>.</p>

<p>All arithmetic operation <code>+</code>, <code>-</code>, <code>*</code>, <code>%</code> and <code>/</code> are supported, <code>%</code> and <code>/</code> standing for remainder and quotient in integer division.</p>

<p>There is also the class <code>modular&lt;m&gt;</code> for performing arithmetic operations on remainders modulo a prime number <code>m</code>.</p>

<p>Other useful functions:</p>

<ul>
<li><code>deriv()</code>: computes the derivative $P'(x)$ of $P(x)$.</li>
<li><code>integr()</code>: computes the indefinite integral $Q(x) = \int P(x)$ of $P(x)$ such that $Q(0)=0$.</li>
<li><code>inv(size_t n)</code>: calculate the first $n$ coefficients of $P^{-1}(x)$ in $O(n \log n)$.</li>
<li><code>log(size_t n)</code>: calculate the first $n$ coefficients of $\ln P(x)$ in $O(n \log n)$.</li>
<li><code>exp(size_t n)</code>: calculate the first $n$ coefficients of $\exp P(x)$ in $O(n \log n)$.</li>
<li><code>pow(size_t k, size_t n)</code>: calculate the first $n$ coefficients for $P^{k}(x)$ in $O(n \log nk)$.</li>
<li><code>deg()</code>: returns the degree of $P(x)$.</li>
<li><code>lead()</code>: returns the coefficient of $x^{\deg P(x)}$.</li>
<li><code>resultant(poly&lt;T&gt; a, poly&lt;T&gt; b)</code>: computes the resultant of $a$ and $b$ in $O(|a| \cdot |b|)$.</li>
<li><code>bpow(T x, size_t n)</code>: computes $x^n$.</li>
<li><code>bpow(T x, size_t n, T m)</code>: computes $x^n \pmod{m}$.</li>
<li><code>chirpz(T z, size_t n)</code>: computes $P(1), P(z), P(z^2), \dots, P(z^{n-1})$ in $O(n \log n)$.</li>
<li><code>vector&lt;T&gt; eval(vector&lt;T&gt; x)</code>: evaluates $P(x_1), \dots, P(x_n)$ in $O(n \log^2 n)$.</li>
<li><code>poly&lt;T&gt; inter(vector&lt;T&gt; x, vector&lt;T&gt; y)</code>: interpolates a polynomial by a set of pairs $P(x_i) = y_i$ in $O(n \log^2 n)$.</li>
<li>And some more, feel free to explore the code!</li>
</ul>

<h2>Arithmetic</h2>

<h3>Multiplication</h3>

<p>The very core operation is the multiplication of two polynomials, that is, given polynomial $A$ and $B$:
$$A = a_0 + a_1 x + \dots + a_n x^n$$
$$B = b_0 + b_1 x + \dots + b_m x^m$$
You have to compute polynomial $C = A \cdot B$: $$\boxed{C = \sum\limits_{i=0}^n \sum\limits_{j=0}^m a_i b_j x^{i+j}}  = c_0 + c_1 x + \dots + c_{n+m} x^{n+m}$$
It can be computed in $O(n \log n)$ via the <a href="./algebra/fft.html">Fast Fourier transform</a> and almost all methods here will use it as subroutine.</p>

<h3>Inverse series</h3>

<p>If $A(0) \neq 0$ there always exists an infinite series $A^{-1}(x) = \sum\limits_{i=0}^\infty a_i'x^i$ such that $A^{-1} A = 1$.</p>

<p>It may be reasonable for us to calculate first $k$ coefficients of $A^{-1}$:</p>

<ol>
<li>Let's say that $A^{-1} \equiv B_k \pmod{x^{a}}$. That means that $A B_k \equiv 1 \pmod {x^{a}}$.</li>
<li>We want to find $B_{k+1} \equiv B_k + x^{a}C \pmod{x^{2a}}$ such that $A B_{k+1} \equiv 1 \pmod{x^{2a}}$: $$A(B_k + x^{a}C) \equiv 1 \pmod{x^{2a}}$$</li>
<li>Note that since $A B_k \equiv 1 \pmod{x^{a}}$ it also holds that $A B_k \equiv 1 + x^a D \pmod{x^{2a}}$. Thus: $$x^a(D+AC) \equiv 0 \pmod{x^{2a}} \implies D \equiv -AC \pmod{x^a} \implies C \equiv -B_k D \pmod{x^a}$$</li>
<li>From this we obtain that:
$$x^a C \equiv -B_k x^a D  \equiv B_k(1-AB_k) \pmod{x^{2a}} \implies \boxed{B_{k+1} \equiv B_k(2-AB_k) \pmod{x^{2a}}}$$</li>
</ol>

<p>Thus starting with $B_0 \equiv a_0^{-1} \pmod x$ we will compute the sequence $B_k$ such that $AB_k \equiv 1 \pmod{x^{2^k}}$ with the complexity: $$T(n) = T(n/2) + O(n \log n) = O(n \log n)$$</p>

<h3>Division with remainder</h3>

<p>Consider two polynomials $A(x)$ and $B(x)$ of degrees $n$ and $m$. As it was said earlier you can rewrite $A(x)$ as:</p>

<p>$$A(x) = B(x) D(x) + R(x), \deg R &lt; \deg B$$</p>

<p>Let $n \geq m$, then you can immediately find out that $\deg D = n - m$ and that leading $n-m+1$ coefficients of $A$ don't influence $R$.</p>

<p>That means that you can recover $D(x)$ from the largest $n-m+1$ coefficients of $A(x)$ and $B(x)$ if you consider it as a system of equations.</p>

<p>The formal way to do it is to consider the reversed polynomials:
$$A^R(x) = x^nA(x^{-1})= a_n + a_{n-1} x + \dots + a_0 x^n$$
$$B^R(x) = x^m B(x^{-1}) = b_m + b_{m-1} x + \dots + b_0 x^m$$
$$D^R(x) = x^{n-m}D(x^{-1}) = d_{n-m} + d_{n-m-1} x + \dots + d_0 x^{n-m}$$</p>

<p>Using these terms you can rewrite that statement about the largest $n-m+1$ coefficients as:</p>

<p>$$A^R(x) \equiv B^R(x) D^R(x) \pmod{x^{n-m+1}}$$</p>

<p>From which you can unambiguously recover all coefficients of $D(x)$:</p>

<p>$$\boxed{D^R(x) \equiv A^R(x) (B^R(x))^{-1} \pmod{x^{n-m+1}}}$$</p>

<p>And from this in turn you can easily recover $R(x)$ as $R(x) = A(x) - B(x)D(x)$.</p>

<h2>Calculating functions of polynomial</h2>

<h3>Newton's method</h3>

<p>Let's generalize the inverse series approach.
You want to find a polynomial $P(x)$ satisfying $F(P) = 0$ where $F(x)$ is some function represented as:
$$F(x) = \sum\limits_{i=0}^\infty \alpha_i (x-\beta)^k$$</p>

<p>Where $\beta$ is some constant. It can be proven that if we introduce a new formal variable $y$, we can express $F(x)$ as:
$$F(x) = F(y) + (x-y)F'(y) + (x-y)^2 G(x,y)$$</p>

<p>Where $F'(x)$ is the derivative formal power series defined as $F'(x) = \sum\limits_{i=0}^\infty (k+1)\alpha_{i+1}(x-\beta)^k$ and $G(x, y)$ is some formal power series of $x$ and $y$.</p>

<p>Given this we can find the coefficients of the solution iteratively:</p>

<ol>
<li>Assume that $F(Q_k) \equiv 0 \pmod{x^{a}}$, we want to find $Q_{k+1} \equiv Q_k + x^a C \pmod{x^{2a}}$ such that $F(Q_{k+1}) \equiv 0 \pmod{x^{2a}}$.</li>
<li>Pasting $x = Q_{k+1}$ and $y=Q_k$ in the formula above we get: $$F(Q_{k+1}) \equiv F(Q_k) + (Q_{k+1} - Q_k) F'(Q_k) + (Q_{k+1} - Q_k)^2 G(x, y) \pmod x^{2a}$$</li>
<li>Since $Q_{k+1} - Q_k \equiv 0 \pmod{x^a}$ we can say that $(Q_{k+1} - Q_k)^2 \equiv 0 \pmod{x^{2a}}$, thus: $$0 \equiv F(Q_{k+1}) \equiv F(Q_k) + (Q_{k+1} - Q_k) F'(Q_k) \pmod{x^{2a}}$$</li>
<li>From the last formula we derive the value of $Q_{k+1}$: $$\boxed{Q_{k+1} = Q_k - \dfrac{F(Q_k)}{F'(Q_k)} \pmod{x^{2a}}}$$</li>
</ol>

<p>Thus knowing how to invert arbitrary polynomial and how to compute $F(Q_k)$ quickly, we can find $n$ coefficients of $P$ with the complexity: $$T(n) = T(n/2) + f(n)$$ Where $f(n)$ is the maximum of $O(n \log n)$ needed to invert series and time needed to compute $F(Q_k)$ which is usually also $O(n \log n)$.</p>

<h3>Logarithm</h3>

<p>For the function $\ln P(x)$ it's known that: $$\boxed{(\ln P(x))' = \dfrac{P'(x)}{P(x)}}$$
Thus we can calculate $n$ coefficients of $\ln P(x)$ in $O(n \log n)$.</p>

<h3>Inverse series</h3>

<p>Turns out, we can get the formula for $A^{-1}$ using Newton's method.
For this we take the equation $A=Q^{-1}$, thus:
$$F(Q) = Q^{-1} - A$$
$$F'(Q) = -Q^{-2}$$
$$\boxed{Q_{k+1} \equiv Q_k(2-AQ_k) \pmod{x^{2^{k+1}}}}$$</p>

<h3>Exponent</h3>

<p>Let's learn to calculate $e^{P(x)}=Q(x)$. It should hold that $\ln Q = P$, thus: $$F(Q) = \ln Q - P$$ $$F'(Q) = Q^{-1}$$ $$\boxed{Q_{k+1} \equiv Q_k(1 + P - \ln Q_k) \pmod{x^{2^{k+1}}}}$$</p>

<h3>$k$-th power</h3>

<p>Now we need to calculate $P^k(x)=Q$. This may be done via the following formula:
$$Q = \exp\left[k \ln P(x)\right]$$
Note though, that you can calculate the logarithms and the exponents correctly only if you can find some initial $Q_0$.</p>

<p>To find it, you should calculate the logarithm or the exponent of the constant coefficient of the polynomial.</p>

<p>But the only reasonable way to do it is if $P(0)=1$ for $Q = \ln P$ so $Q(0)=0$ and if $P(0)=0$ for $Q = e^P$ so $Q(0)=1$.</p>

<p>Thus you can use formula above only if $P(0) = 1$. Otherwise if $P(x) = \alpha x^t T(x)$ where $T(0)=1$ you can write that:
$$\boxed{P^k(x) = \alpha^kx^{kt} \exp[k \ln T(x)]}$$
Note that you also can calculate some $k$-th root of a polynomial if you can calculate $\sqrt[k]{\alpha}$, for example for $\alpha=1$.</p>

<h2>Evaluation and Interpolation</h2>

<h3>Chirp-z Transform</h3>

<p>For the particular case when you need to evaluate a polynomial in the points $x_r = z^{2r}$ you can do the following:</p>

<p>$$A(z^{2r}) = \sum\limits_{k=0}^n a_k z^{2kr}$$</p>

<p>Let's substitute $2kr = r^2+k^2-(r-k)^2$. Then this sum rewrites as:</p>

<p>$$\boxed{A(z^{2r}) = z^{r^2}\sum\limits_{k=0}^n (a_k z^{k^2}) z^{-(r-k)^2}}$$</p>

<p>Which is up to the factor $z^{r^2}$ equal to the convolution of the sequences $u_k = a_k z^{k^2}$ and $v_k = z^{-k^2}$.</p>

<p>Note that $u_k$ has indexes from $0$ to $n$ here and $v_k$ has indexes from $-n$ to $m$ where $m$ is the maximum power of $z$ which you need.</p>

<p>Now if you need to evaluate a polynomial in the points $x_r = z^{2r+1}$ you can reduce it to the previous task by the transformation $a_k \to a_k z^k$.</p>

<p>It gives us an $O(n \log n)$ algorithm when you need to compute values in powers of $z$, thus you may compute the DFT for non-powers of two.</p>

<h3>Multi-point Evaluation</h3>

<p>Assume you need to calculate $A(x_1), \dots, A(x_n)$. As mentioned earlier, $A(x) \equiv A(x_i) \pmod{x-x_i}$. Thus you may do the following:</p>

<ol>
<li>Compute a segment tree such that in the segment $[l,r)$ stands the product $P_{l, r}(x) = (x-x_l)(x-x_{l+1})\dots(x-x_{r-1})$.</li>
<li>Starting with $l=1$ and $r=n$ at the root node. Let $m=\lfloor(l+r)/2\rfloor$. Let's move down to $[l,m)$ with the polynomial $A(x) \pmod{P_{l,m}(x)}$.</li>
<li>This will recursively compute $A(x_l), \dots, A(x_{m-1})$, now do the same for $[m,r)$ with $A(x) \pmod{P_{m,r}(x)}$.</li>
<li>Concatenate the results from the first and second recursive call and return them.</li>
</ol>

<p>The whole procedure will run in $O(n \log^2 n)$.</p>

<h3>Interpolation</h3>

<p>There's a direct formula by Lagrange to interpolate a polynomial, given set of pairs $(x_i, y_i)$:</p>

<p>$$\boxed{A(x) = \sum\limits_{i=1}^n y_i \prod\limits_{j \neq i}\dfrac{x-x_j}{x_i - x_j}}$$</p>

<p>Computing it directly is a hard thing but turns out, we may compute it in $O(n \log^2 n)$ with a divide and conquer approach:</p>

<p>Consider $P(x) = (x-x_1)\dots(x-x_n)$. To know the coefficients of the denominators in $A(x)$ we should compute products like: $$P_i = \prod\limits_{j \neq i} (x_i-x_j)$$</p>

<p>But if you consider the derivative $P'(x)$ you'll find out that $P'(x_i) = P_i$. Thus you can compute $P_i$'s via evaluation in $O(n \log^2 n)$.</p>

<p>Now consider the recursive algorithm done on same segment tree as in the multi-point evaluation. It starts in the leaves with the value $\dfrac{y_i}{P_i}$ in each leaf.</p>

<p>When we return from the recursion we should merge the results from the left and the right vertices as $A_{l,r} = A_{l,m}P_{m,r} + P_{l,m} A_{m,r}$.</p>

<p>In this way when you return back to the root you'll have exactly $A(x)$ in it.
The total procedure also works in $O(n \log^2 n)$.</p>

<h2>GCD and Resultants</h2>

<p>Assume you're given polynomials $A(x) = a_0 + a_1 x + \dots + a_n x^n$ and $B(x) = b_0 + b_1 x + \dots + b_m x^m$.</p>

<p>Let $\lambda_0, \dots, \lambda_n$ be the roots of $A(x)$ and let $\mu_0, \dots, \mu_m$ be the roots of $B(x)$ counted with their multiplicities.</p>

<p>You want to know if $A(x)$ and $B(x)$ have any roots in common. There are two interconnected ways to do that.</p>

<h3>Euclidean algorithm</h3>

<p>Well, we already have an <a href="./algebra/euclid-algorithm.html">article</a> about it. For an arbitrary euclidean domain you can write the Euclidean algorithm as easy as:</p>

<pre><code class="cpp">template&lt;typename T&gt;
T gcd(const T &amp;a, const T &amp;b) {
    return b == T(0) ? a : gcd(b, a % b);
}
</code></pre>

<p>It can be proven that for polynomials $A(x)$ and $B(x)$ it will work in $O(nm)$.</p>

<h3>Resultant</h3>

<p>Let's calculate the product $A(\mu_0)\cdots A(\mu_m)$. It will be equal to zero if and only if some $\mu_i$ is the root of $A(x)$.</p>

<p>For symmetry we can also multiply it with $b_m^n$ and rewrite the whole product in the following form:
$$\boxed{\mathcal{R}(A, B) = b_m^n\prod\limits_{j=0}^m A(\mu_j) = b_m^n a_m^n \prod\limits_{i=0}^n \prod\limits_{j=0}^m (\mu_j - \lambda_i)= (-1)^{mn}a_n^m \prod\limits_{i=0}^n B(\lambda_i)}$$</p>

<p>The value defined above is called the resultant of the polynomials $A(x)$ and $B(x)$. From the definition you may find the following properties:</p>

<ol>
<li>$\mathcal R(A, B) = (-1)^{nm} \mathcal R(B, A)$.</li>
<li>$\mathcal R(A, B)= a_n^m b_m^n$ when $n=0$ or $m=0$.</li>
<li>If $b_m=1$ then $\mathcal R(A - CB, B) = \mathcal R(A, B)$ for an arbitrary polynomial $C(x)$ and $n,m \geq 1$.</li>
<li>From this follows $\mathcal R(A, B) = b_m^{\deg(A) - \deg(A-CB)}\mathcal R(A - CB, B)$ for arbitrary $A(x)$, $B(x)$, $C(x)$.</li>
</ol>

<p>Miraculously it means that resultant of two polynomials is actually always from the same ring as their coefficients!</p>

<p>Also these properties allow us to calculate the resultant alongside the Euclidean algorithm, which works in $O(nm)$.</p>

<pre><code class="cpp">template&lt;typename T&gt;
T resultant(poly&lt;T&gt; a, poly&lt;T&gt; b) {
    if(b.is_zero()) {
        return 0;
    } else if(b.deg() == 0) {
        return bpow(b.lead(), a.deg());
    } else {
        int pw = a.deg();
        a %= b;
        pw -= a.deg();
        base mul = bpow(b.lead(), pw) * base((b.deg() &amp; a.deg() &amp; 1) ? -1 : 1);
        base ans = resultant(b, a);
        return ans * mul;
    }
}
</code></pre>

<h3>Half-GCD algorithm</h3>

<p>There is a way to calculate the GCD and resultants in $O(n \log^2 n)$. To do this you should note that if you consider $a(x) = a_0 + x^k a_1$ and $b(x) = b_0 + x^k b_1$ where $k=\min(\deg a, \deg b)/2$ then basically the first few operations of Euclidean algorithm on $a(x)$ and $b(x)$ are defined by the Euclidean algorithm on $a_1(x)$ and $b_1(x)$ for which you may also calculate GCD recursively and then somehow memorize linear transforms you made with them and apply it to $a(x)$ and $b(x)$ to lower the degrees of polynomials. Implementation of this algorithm seems pretty tedious and technical thus it's not considered in this article yet.</p>

<h2>Problems</h2>

<ul>
<li><a href="https://www.codechef.com/problems/RNG">CodeChef - RNG</a></li>
<li><a href="https://codeforces.com/gym/102129/problem/D">CodeForces - Basis Change</a></li>
<li><a href="https://codeforces.com/gym/102129/problem/G">CodeForces - Permutant</a></li>
<li><a href="https://codeforces.com/gym/102129/problem/C">CodeForces - Medium Hadron Collider</a></li>
</ul>

    <div id="footer">
    (c) 2014-2021 translation by <a href="http://github.com/e-maxx-eng">http://github.com/e-maxx-eng</a>
    </div>
</div>

<script>
if (/e\-maxx\-eng|cp\-algorithms/.test(location.href)) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-85220282-1', 'auto');
  ga('send', 'pageview');
}
</script>
</body>
</html>
